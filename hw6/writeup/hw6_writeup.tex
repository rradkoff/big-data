\documentclass[11pt, fleqn]{article}

\input{header.tex}

\setlength{\parskip}{12pt} % Sets a blank line in between paragraphs
\setlength\parindent{0pt} % Sets the indent for each paragraph to zero

\begin{document}

\title{Big Data: Homework 6}
\author{Will Clark \& Matthew DeLio \\ 41201-01}
\date{\today}
\maketitle

\section{K-Means Clustering} \label{sec:kmeans}

In this section, we cluster the 109th Congress phrase-counts to see what information can be obtained.  We employ the K-Means clustering algorithm.  To choose the ``optimal'' cluster size, we varied the cluster size from 2 to 35 and then selected the number of clusters $K$ with the minimum BIC, which should\textemdash hopefull\textemdash produce good OOS clustering results.  \Vref{fig:kmeans_ic_plot} shows a plot of the information criteria while varying K; while the BIC finds a minima at 15, the AICc never reaches a minima.

As discussed in class, these information criteria are of lower-quality than those used for regression.  A quick glance at \vref{tab:k_means_summary} backs up this theory, as there are several clusters with just a single representative (leading us to believe that the cluster is overfitting), and no clear divide between the Democrats, Republicans, and Independents.  A quick glance at the top three phrases used in each cluster is shown in \vref{tab:g_words}; we can see that cluster phrases can be rather random.  Additionally, the bulk of the representatives are contained in a single cluster.  %However, when the algorithm does have a clear separation between democrat and republican representatives, there is a clear divide.  Combining information from the cluster summary (\cref{tab:k_means_summary}) and the top three phrases table (\cref{tab:k_means_3}) phrases such as ``program.help'' vs ``illegal.immigration'' for Democrats and Republicans respectively indicate that the algorithm can cluster based on some partisan phrases.

We can pick one phrase from this clustering model to understand the results a little more clearly. We show the incidences of the phrase ``stem.cel'' in \vref{tab:stemcell}. We see that there is a particulary high use of this phrase in two clusters (6 and 14). Representatives in cluster 14 use this phrase more than 20 standard deviations more than the average representative. In our run, cluster 14 is just one Republican representative named Roscoe Bartlett, who during his career was very active in searching for a common ground between the parties on stem cell research\footnote{``The Congressman Who Went Off the Grid'', \textit{Politico Magazine}, January 2014.}. This suggests that rather than just identifying party affiliation, the K-means clustering is also identifying pet issues of certain representatives.

\input{stemcell}

As a final note, for an experiment to see if K-means would do a better job clustering the two parties, we ran k-means with a cluster-size of 2 \& 3.  In both instances (see \vref{tab:k_means_3} for K=3), the bulk of the representatives were clustered together as when K=15.  This raises the question: are the two parties really all that different after all? Our crude textual analysis suggests they are not.

\begin{figure}[!htb]
  \centering
  \includegraphics[scale=.5]{kmeans_ic_plot.eps}
  \caption{Informaton Criteria for Varying K-means}
  \label{fig:kmeans_ic_plot}
\end{figure}

\input{g_words.tex}

\section{Topic Model}

A topic model was constructed using the \texttt{topics} command in R. The text of each member's speeches is a document, and the document is composed of different topics. Each topic is a probabilistic mixture of words likely to be used in that topic. We can only observe the documents and the words; what we do not know is the extent to which each document is composed of different topics. The \texttt{topics} attempts to do this for us.

The top three phrases for each topic (sorted by largest $P(phrase_i|topic_k)$) are found in \vref{tab:tpcs3}.  These phrases do indicate that this method does a really good job of finding related phrases.  There are few clusters that could probably be merged or otherwise modified.  However, the vast majority of topics contain phrases that are very much inter-related; they are, in fact topics.  For example, the first topic appears to be about budget issues, the third about free trade legislation, etc.

\input{tpcs3.tex}

\section{Connecting Unsupervised Clusters to Partisanship}
\subsection{Party Membership by K-means Cluster}
See \vref{tab:k_means_summary} for the party membership by K-means cluster.  As mentioned in Section~\cref{sec:kmeans}, the K-means clustering does not yield a ton of useful information about a representative's affiliation.  There are a handful of senators and congressman that are clearly grouped into their party, however, the vast majority end up in a single cluster.  This is likely because they argue against each other and therefore use each others' words in their speeches.  However, if taken at face-value, the cluster with almost an equal amount of republican and democratic members would likely denote phrases that are considered non-partisan.  These ``non-partisan'' phrases are found in \vref{tab:k_means_nonpart}, and do actually tend to indicate non-partisan phrases (we assume that post offices and wild birds are safely non-partisan).

\input{k_means_summary.tex}
\input{k_means_nonpart.tex}

\subsection{Non-Partisan Topics}

Here we plot the topic frequencies based on party affiliation.  \Vref{fig:topic} clearly shows that some topics are much more partisan than others.  For the topics with large deviation between the two parties, we can (using \vref{tab:tpcs3}) see that some topics, such as illegal immigration and civil rights, tend to align with our intuition on which phrases would be used more often by party members.  For the most part, these differences in frequencies exist and are quite noticeable.  However, one of the topics (\#7) appears to be non-partisan.  \Vref{tab:non_part_topics} shows the top 10 phrases from that topic and intuition confirms that many of these phrases are fairly non-partisan (as before, the postal service, drinking water, and endangered species cannot be too partisan).

\begin{figure}[!htb]
  \centering
  \includegraphics[scale=.5]{topic.eps}
  \caption{Partisan Topic Frequencies}
  \label{fig:topic}
\end{figure}

\input{non_part_topics.tex}

\subsection{Party Membership/Share by Topic}

In this section, we use the results from the topic clustering to predict party membership.  We employ a gamma lasso with and without cross-validation to regress political affiliation onto the topic $\omega$'s chosen for each representative.  In general $\omega$'s give the percentage of a document (in this case a collection of speeches by a representative) that belongs to a given topic.  The hope is that the topics that are more likely to be discussed by, say a Democrat, would help predict their party affiliation.  The gamma lasso and the cross-validated gamma lasso both include all 13 topics in the model, but completely disagree on the values of the information criteria (likely due to the small number of degrees of freedom).  \Vref{tab:topic_rep} shows that all three of the information criteria choose all 13 covariates and provide an in-sample $R^2$ of 56\%.  The OOS $R^2$ for the model chosen by cv.gamlr (using the CV.min rule) is a bit lower at $R^2=52\%$.

\input{topic_rep.tex}

Here we regress the ``republican share'' onto our topics.  While very similar to regressing the party membership above, this measure allows us to determine how much a the use of certain topics will predict how large the republican share is in one's district.  Note, that this might not predict who is a democrat vs a republican; in fact, we would expect that in contested districts/states, the republican share to be quite large even if the sitting representative is a democrat.  As before the gamma lasso with/without cross-validation is performed; the results are shown in \vref{tab:topic_repshare}.  Again we see that the in-sample $R^2$ each of the ICs is 37\%.  Using cross-validation and the CV.min selection rule, this $R^2$ drops to 35\%, just a touch lower than the in-sample ones.

\input{topic_repshare.tex}

Finally, we regress the party affiliation and republican share (separately) onto phrase frequency (measured in \%).  From \vref{tab:repx,tab:repsharex}, we see that, in both cases, AICc and CV.Min disagree quite a bit on the number of covariates to include.  Also, in-sample predictive power for the republican share (using AICc) is much higher than the out-of-sample one predicted/measured by the cross-validated gamma lasso.  Similarly, the $\lambda$ and $R^2$ found using AICc and CV.Min for the party affiliation also disagree widely.  This tends to indicate the phrase percentage is not a great predictor of either of these measures of partisanship. 

\input{repx.tex}
\input{repsharex.tex}

\Vref{tab:repx_coef_p,tab:repx_coef_n} show both the positive and negative the phrase percentage coefficients that predict the odds of a representative being a republican.  The signals selected are intuitively quite good; however, there are not too many signals actually selected in the end (only 4 signals that increase the odds of a republican and 32 that decrease).  The model is perhaps underfit by the AICc, but, ultimately, by not distilling the phrases into a more usable form, the signals, by themselves are just not that strong.  In this sense, the distillation of the phrases into topics gives us a powerful tool to analyze data.

\input{repx_coef_p.tex}
\input{repx_coef_n.tex}


\clearpage
\section{Appendix}

\input{k_means_3.tex}

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{tpcs_rep.eps}
    \caption{Regressing Party Affiliation}
    \label{fig:tpcs_rep}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{tpcs_rep_share.eps}
    \caption{Regressing District Republican Share}
    \label{fig:tpcs_repshare}
  \end{subfigure}
  \caption{Topics as Predictors}
\end{figure}

\begin{figure}
  \centering
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{reg_phrase_pcnt.eps}
    \caption{Regressing Party Affiliation}
    \label{fig:pcnt_rep}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{reg_phrase_pcnt_repshare.eps}
    \caption{Regressing District Republican Share}
    \label{fig:pcnt_rep_share}
  \end{subfigure}
  \caption{Phrase \% as Predictors}
\end{figure}


% \input{.tex}

% \begin{figure}
%   \centering
%   \begin{subfigure}[b]{0.49\textwidth}
%     \includegraphics[width=\textwidth]{.eps}
%     \caption{}
%     \label{fig:}
%   \end{subfigure}
%   \hfill
%   \begin{subfigure}[b]{0.49\textwidth}
%     \includegraphics[width=\textwidth]{.eps}
%     \caption{}
%     \label{fig:}
%   \end{subfigure}
%   \caption{}
% \end{figure}

% \begin{figure}[!htb]
%   \centering
%   \includegraphics[scale=.5]{.eps}
%   \caption{}
%   \label{fig:}
% \end{figure}

\end{document}